---
title: "Section 3_student"
author: "Haemin Jee"
date: "1/25/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Setting up Iraq War Vote dataset

### 1.1

We're going to continue analyzing the Senate's vote on the Iraq war authorization. This data set is in the PSCL package, called `pscl` in R.

You should have already downloaded it so please load the library. 

```{r}
rm(list=ls())
#setwd('~/Dropbox/150B Machine Learning/03_Section') #Haemin
setwd("~/Dropbox (IPL)/150B Machine Learning/03_Section") #Tongtong
library(pscl)
```

To load the data set, execute the following code.

```{r}
data(iraqVote)
```

To recap, the variables in the data set are:
- y : The vote on the Iraq war authorization
- state.abb : Name of the senator's state
- name : senator's name
- rep : an indicator = TRUE if the senator is a Republican, FALSE if not a Republican
- state.name : the name of the senator's state
- gorevote: the share of the two party vote cast for Al Gore in the 2000 election

### 1.2

Let's run a linear proabability model in. Then, let's write a function that takes the predicted probabilities and a threshold, and returns a classification decision. Use that function to classify each senator as Yay or Nay on the Iraq vote.
```{r}

lpm <- lm(y ~ rep + gorevote, data = iraqVote)

# getting predicted probabilities
# predict is the canned function in R to do this
pred_prob_lm <- predict(lpm, newdata = iraqVote)

# function inputting probability vector and threshold, returns class vector
class_func <- function(prob, threshold){
  class <- ifelse(prob>threshold, 1, 0)
  return(class)
}

# estimate class on predicted probabilities
# choose threshold
class_lm <- class_func(pred_prob_lm, 0.5)

# take a peek
head(class_lm)
```
Now that we have the set up, let's move on the Logistic Regression

## 2. Fitting a Logistic Regression

## 2.1

Fitting a logistic regression is a generalization of fitting a linear regression. Let's work through an example of a logistic regression together.

We're fitting a simple logistic regression of the vote decision against Republican. To do this, we'll use the `glm` function.
```{r}
# CODE HERE
rep_reg <- 
```

- `glm` stands for generalized linear model.
- `y` is the dependent variable here.
- `rep` is the independent variable.

We specify `family = binomial` to let glm know that we're interested in a logistic regression. And just like `lm`, data is how we specify the data we'll use.

We can check what is available in the object:
```{r}
names(rep_reg)
```

Let's extract those predicted probabilities with:
```{r}
head(rep_reg$fitted.values)
```

### 2.2:

Fit a logistic regression of `y` on `rep` and `gorevote`. Store it in an object called `gore_reg`.
```{r}
gore_reg <- 
```

### 2.3
In Homework 1, we asked you to write a function to calculate predicted probabilities from a linear regression model. Let's try to write a function that will do that for logistic regression. To do this, we need to write a function for the logistic function (or the inverse logit).
```{r}

inv_logit <- function(value){
  solve <- 1 / (1+exp(-value))
  return(solve)
}

# We will see why this becomes important when finding the predicted probability

pred_prob_logit <- function(model, values){

}

ivs <- cbind(1, iraqVote[, c("rep", "gorevote")])

my_pred_logit <- pred_prob_logit(model = gore_reg, values = ivs)
```

Retrive the predicted probabilities from the model above and store it in an object `logist_gore_preds`.
```{r}
logist_gore_preds <- gore_reg$fitted.values

# Using the predict function

predict_preds <- predict(gore_reg, newdata = iraqVote, family = "binomial", type = "response")

# Check if all of these give me the same thing
head(predict_preds)
head(logist_gore_preds)
head(my_pred_logit)
```

### 2.4

The code below plots the predicted probabilities from the linear model and the logistic regression. Using this plot, how do the predicted probabilities of the two functions differ?
```{r}
plot(pred_prob_lm ~ c(logist_gore_preds), xlab = 'Logistic predictions', ylab = 'Linear predictions')
abline(h =1)
abline(v = 1)
# what does this graph tell us about the difference between LPM and logistic? 
```

### 2.5

Now, using the probabilities and the classification function and threshold from earlier, classify the senators using the logistic regression function.
```{r}
class_gore_preds <- 
  
# take a peek
head(class_gore_preds)
```

### 2.6

Using `table`, compare the classification from the linear model and the logistic regression. What do you notice?
```{r}

```

### 3. Model Evaluation 

### 3.1 

We are now ready to begin evaluating our model. We want to write three functions to calculate:
1) Accuracy
2) Precision
3) Recall

Let's write the accuracy functions together 

```{r}
accuracy <- function(predicted, true){

  
}

precision <- function(predicted, true){

  
}

recall <- function(predicted, true){

  
}

```

### 3.2

The code below uses the functions compare the accuracy, precision, and recall of the LM classifications and the logistic regression predicions. On the basis of these scores, can you make a strong argument for selecting either model?  
```{r}
cat('Linear Regression', '\n')
cat('Accuracy', '\n'); accuracy(class_lm, iraqVote$y)
cat('Precision', '\n'); precision(class_lm, iraqVote$y)
cat('Recall', '\n'); recall(class_lm, iraqVote$y)

cat('Logistic Regression', '\n')
cat('Accuracy', '\n'); accuracy(class_gore_preds, iraqVote$y)
cat('Precision', '\n'); precision(class_gore_preds, iraqVote$y)
cat('Recall', '\n'); recall(class_gore_preds, iraqVote$y)
```


### 3.3 

Finally, what happens as we vary the threshold on our classification? Let's focus on the predictions from the logistic regression. 

Using a for loop, assess how the precision, recall, and f scores varies as the threshold moves from 0 to 1.

```{r}
# create a vector of different threshold possibilities
thresh <- seq(0.0, 1, len = 1000)

# loop through and calculate classes based on these probabilities
store_f <- store_prec <- store_rec <- c()

for(z in 1:length(thresh)){
  
  
  
}

# Let's plot the F-statistic
plot(x = thresh, y=store_f, type = "l", main = "F scores", ylab = "F Scores", 
     xlab = "Threshold")
```
